# -*- coding: utf-8 -*-
"""Gap_filling_MLR_RF_XGB_QM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dD2H5za8hsDQBpIdBSSz7H6O9EMA2T11
"""

# ===============================
# Water Stress Prediction Models
# MLR, RF, XGBoost, Quantile Mapping
# Author: [Your Name]
# Date: [2025-07-22]
# ===============================

# ==== STEP 1: Install Required Packages====

!pip install xgboost openpyxl scikit-learn matplotlib pandas --quiet

# ==== STEP 2: Import Libraries ====
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

# ==== STEP 3: Load Excel File ====
def load_excel_file(filepath):
    df = pd.read_excel(filepath)
    print("✅ Excel file loaded successfully")
    return df

# ==== STEP 4: Prepare Data ====
def prepare_data(df, input_cols, target_cols):
    df_model = df.dropna(subset=input_cols + target_cols)
    X = df_model[input_cols]
    y1 = df_model[target_cols[0]]
    y2 = df_model[target_cols[1]]
    return train_test_split(X, y1, test_size=0.2, random_state=42), train_test_split(X, y2, test_size=0.2, random_state=42)

# ==== STEP 5: Model Training ====
def train_models(X_train, y_train, model_type='MLR'):
    if model_type == 'MLR':
        return LinearRegression().fit(X_train, y_train)
    elif model_type == 'RF':
        params = {'n_estimators': [100], 'max_depth': [None], 'min_samples_split': [2], 'min_samples_leaf': [1]}
        return GridSearchCV(RandomForestRegressor(random_state=42), params, cv=3).fit(X_train, y_train).best_estimator_
    elif model_type == 'XGB':
        params = {'n_estimators': [100], 'max_depth': [3], 'learning_rate': [0.1], 'subsample': [1.0]}
        return GridSearchCV(XGBRegressor(objective='reg:squarederror', random_state=42), params, cv=3).fit(X_train, y_train).best_estimator_

# ==== STEP 6: Quantile Mapping ====
def true_quantile_mapping(sar_values, sar_ref, lswi_ref):
    sar_sorted = np.sort(sar_ref)
    lswi_sorted = np.sort(lswi_ref)
    percentiles = np.linspace(1 / len(sar_sorted), 1, len(sar_sorted))
    sar_percentiles = np.interp(sar_values, sar_sorted, percentiles)
    return np.interp(sar_percentiles, percentiles, lswi_sorted)

# ==== STEP 7: Location-based Subsets ====
def get_location_subsets(df):
    return {
        'Jodhpur': df.iloc[0:27],
        'Nagpur': df.iloc[27:102],
        'Barrackpore': df.iloc[102:151]
    }

# ==== STEP 8: Plotting Function ====
def plot_predictions(df, locations):
    fig, axs = plt.subplots(4, 6, figsize=(22, 14))
    for i, method in enumerate(['MLR', 'RF', 'XGB', 'QM']):
        for j, (ws, pred_prefix) in enumerate([('WS1', 'WS1_'), ('WS2', 'WS2_')]):
            for k, (loc_name, loc_df) in enumerate(locations.items()):
                ax = axs[i, j*3 + k]
                actual = loc_df[ws]
                pred_col = f"{pred_prefix}{method}" if method != "QM" else f"{ws}_QM"
                if pred_col not in loc_df or ws not in loc_df:
                    ax.text(0.5, 0.5, "Missing Data", ha='center', va='center')
                    ax.set_axis_off()
                    continue
                pred = loc_df[pred_col]
                mask = actual.notna() & pred.notna()
                if mask.sum() == 0:
                    ax.text(0.5, 0.5, "No valid data", ha='center', va='center')
                    ax.set_xlim(0.2, 1)
                    ax.set_ylim(0.2, 1)
                    continue
                # Plot
                ax.scatter(actual[mask], actual[mask], c='blue', s=15, alpha=0.5, label='Actual')
                ax.scatter(actual[mask], pred[mask], c='gold', edgecolors='k', s=15, alpha=0.7, label='Predicted')
                ax.plot([0, 1], [0, 1], 'r--', linewidth=0.8)
                ax.set_xlabel("Actual", fontsize=9)
                ax.set_ylabel("Predicted", fontsize=9)
                if i == 0:
                    ax.set_title(loc_name, fontsize=11)
                if j == 0 and k == 0:
                    ax.set_ylabel(method, rotation=0, fontsize=11, labelpad=30)
                # Axis limits
                if ws == 'WS1':
                    ax.set_xlim(0.86, 1)
                    ax.set_ylim(0.86, 1)
                else:
                    ax.set_xlim(0.0, 1)
                    ax.set_ylim(0.0, 1)
                # R² and RMSE
                if k == 2:
                    r2 = r2_score(actual[mask], pred[mask])
                    rmse = np.sqrt(mean_squared_error(actual[mask], pred[mask]))
                    ax.text(1.02, 0.92, f'R²={r2:.2f}', transform=ax.transAxes, fontsize=9)
                    ax.text(1.02, 0.80, f'RMSE={rmse:.2f}', transform=ax.transAxes, fontsize=9)
    # Titles & Legend
    fig.text(0.23, 0.94, "WS1", fontsize=14, fontweight='bold')
    fig.text(0.68, 0.94, "WS2", fontsize=14, fontweight='bold')
    fig.suptitle("Model-wise Predicted vs Actual (1:1 Scatter Plots)", fontsize=16)
    handles = [
        plt.Line2D([], [], color='blue', marker='o', linestyle='None', label='Actual'),
        plt.Line2D([], [], color='gold', marker='o', markeredgecolor='k', linestyle='None', label='Predicted'),
        plt.Line2D([], [], color='red', linestyle='--', label='1:1 Line')
    ]
    fig.legend(handles=handles, loc='lower center', ncol=3, fontsize=12)
    plt.tight_layout(rect=[0, 0.05, 1, 0.95])
    plt.show()

# ==== MAIN EXECUTION ====
if __name__ == '__main__':
    # === File Path ===
    excel_path = '/content/DATA_PREPARATION2.xlsx'  # <- Change this before running

    # === Step A: Load and Prepare ===
    df = load_excel_file(excel_path)
    input_cols = ['VH/VV', 'VH-VV', '(VH-VV)/(VH+VV)', 'RVI']
    target_cols = ['LSWI1', 'LSWI2']
    (X_train1, X_test1, y_train1, y_test1), (X_train2, X_test2, y_train2, y_test2) = prepare_data(df, input_cols, target_cols)

    # === Step B: Train Models ===
    mlr1 = train_models(X_train1, y_train1, 'MLR')
    mlr2 = train_models(X_train2, y_train2, 'MLR')
    rf1 = train_models(X_train1, y_train1, 'RF')
    rf2 = train_models(X_train2, y_train2, 'RF')
    xgb1 = train_models(X_train1, y_train1, 'XGB')
    xgb2 = train_models(X_train2, y_train2, 'XGB')

    # === Step C: Predict for all rows ===
    df['WS1'] = df['LSWI1']
    df['WS2'] = df['LSWI2']
    for model, name in zip([mlr1, rf1, xgb1], ['MLR', 'RF', 'XGB']):
        df[f'WS1_{name}'] = model.predict(df[input_cols])
    for model, name in zip([mlr2, rf2, xgb2], ['MLR', 'RF', 'XGB']):
        df[f'WS2_{name}'] = model.predict(df[input_cols])

    # === Step D: Apply Quantile Mapping ===
    sar_col = '(VH-VV)/(VH+VV)'
    for ws in ['WS1', 'WS2']:
        ref = df[[sar_col, ws]].dropna()
        sar_vals = ref[sar_col]
        ws_vals = ref[ws]
        df[f'{ws}_QM'] = df[sar_col].apply(lambda x: true_quantile_mapping([x], sar_vals, ws_vals)[0] if pd.notna(x) else np.nan)

    # === Step E: Plot ===
    locations = get_location_subsets(df)
    plot_predictions(df, locations)

# ==== STEP F: Export to Excel ====
output_path = "/content/WaterStress_Model_Output.xlsx"
df.to_excel(output_path, index=False)
print(f"✅ Output Excel file saved at: {output_path}")